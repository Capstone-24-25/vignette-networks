---
title: "Network Analysis Vignette"
author: "Ivy Li, Yamileth Martinez, Jade O'Brien"
date: today
format: html
---

# Overview

In this vignette, we will explore basic network analysis using the `igraph` package on the `congress_network` dataset. Network analysis helps us explore and understand the structure of a network; in this case, the Twitter interactions of the 117th Congress. Our objective in this vignette is to give a basic overview of how to use the `igraph` package for data visualization, and to analyze whether particular attributes such as party affiliation, chamber, and the geographical region of a member of Congress influences who they interact with on Twitter. We will additionally cover centrality metrics, graph metrics, bootstrap hypothesis testing, and adjacency matrices.

# Data

The `congress_network_data.json` file is a network that represents the Twitter interaction network for the 117th United States Congress, taking into account the House of Representatives as well as the Senate. The `congress_node_attributes` file contains vertex attributes that include the name of the congressperson, their respective chamber, party affiliation, state, and Census Bureau-designated region of the state. The `congress_network_data.json` files can be downloaded [here](https://snap.stanford.edu/data/congress-twitter.html) from Stanford's SNAP website. The data in the `congress_node_attributes` file was collected independently.

# Methodology

We perform our analysis in R using the `rjson` and `igraph` packages. We read in the data from the `rjson` file using our preprocessing script, as shown below. To read in the data from a `json` file, we transformed the data into a dataframe.

```{r, message = FALSE}
source(here::here("scripts/preprocessing.R"))
library(tidyverse)
library(rjson)
library(igraph)
library(knitr)
library(Matrix)

# Read in the JSON file
network_json <- fromJSON(file = here::here("data/congress_network/congress_network_data.json"))

# Use the preprocessing function
network_df <- cnet_json_to_df(network_json)

# Create congress twitter graph
cnet_igraph <- create_cnet_igraph(network_df)

```

# Important Terms and Information

When dealing with network data observations are typically referred to as *nodes* or *vertices*, and the connections between them are called *edges*.

*Node attributes* are the properties of individual observations, like someone's age. Whereas *edge attributes* are information about the relationships between nodes, such as the type of relationship or its strength. 

Additionally, network data can be directed or undirected. In a directed network, edges originate from a particular node (known as the *source*) and terminate in another (known as the *target*). In contrast  no such directionality exists for undirected networks. For example, if we had data on a network of people in a gift exchange, this could be represented as a directed network where edges originate from the person giving a gift and terminate at the person receiving that particular gift.

The data that we will be analyzing in this vignette is a weighted, directed network. This means that our edges have direction, and that there is a single edge attribute, known as the weight. The edge weights in this data are referred to as transmission weights and they essentially represent the probability that the source retweets, quote tweets, replies to, or mentions the target after the target tweets. 


# Data Visualization

The primary R package for creating network visualizations is igraph. By converting the rjson file into a dataframe and incorporating the congress_node_attributes file, we can leverage the capabilities of igraph to generate detailed network visualizations. This package enables visualization of the entire network as well as its subgroups. Node colors in the visualizations are based on party affiliation, providing clear distinctions between groups. Our objective is to enhance these visualizations through random sampling techniques. Below, we attempt to create a visualization of the complete network.


```{r}
V(cnet_igraph)$color <- ifelse(V(cnet_igraph)$party == "D", "blue", 
                      ifelse(V(cnet_igraph)$party == "R", "red", "gray"))
plot(cnet_igraph,
     main = "Complete Network Graph")
```

As shown, the initial plot is cluttered and difficult to interpret due to the excessive number of nodes, and no specific attribute was assigned as vertex labels. Additionally, node colors are determined by party affiliation, highlighting group differences.

To address this, we created subgraphs by filtering the nodes based on specific attributes, such as region. In the subgraph below, we focused on the Midwest and South regions, with nodes in the Midwest colored orange, nodes in the South colored purple, and all other nodes colored gray. This allows us to clearly distinguish between these regions while maintaining the overall structure of the network.

```{r}
# filter nodes by attributes (party or region)
sub_nodes <- V(cnet_igraph)[party %in% c("D", "R") | region %in% c("Midwest", "South")]

sub_g <- induced_subgraph(cnet_igraph, vids = sub_nodes)

# colors based on region
V(sub_g)$color <- ifelse(V(sub_g)$region == "Midwest", "orange", 
                      ifelse(V(sub_g)$region == "South", "purple", "gray"))

plot(sub_g,
     main = "Subgraph of Filtered Nodes (Region)")
```

Similar to the first plot, this visualization also suffers from readability issues due to the dense network. To address this, we applied a similar approach to simplify the graph.

Below, we randomly sampled individuals from the attributes dataframe and matched them to their connections in the network dataframe to create a plot of this random sample. The node colors in the plot are determined by party affiliation, enhancing the visual distinction between groups. While not depicted here, additional noise reduction can be achieved by filtering the data based on specific attributes.

```{r}
# load in node attributes
cnet_node_attributes <- read_csv("data/congress_node_attributes.csv",
                                 show_col_types = FALSE)

# sample from node attributes, then name in sample 
set.seed(123)
sample_indices <- sample(nrow(cnet_node_attributes), size = 25)
sample_nodes <- cnet_node_attributes[sample_indices,]

# want to make sure the attributes and nodes match
id_node <- sample_nodes$node
id_from <- network_df$from
id_to <- network_df$to
net_sam <- data.frame(from = double(),
                      to = integer(),
                      weight = double())

for (i in id_node){
  if (i %in% id_to | i %in% id_from){
    matches_from <- subset(network_df, from == i)
    matches_to <- subset(network_df, to == i)
    net_sam <- rbind(net_sam, matches_from, matches_to)
  }
}

net_sam <- subset(net_sam, from %in% sample_nodes$node & to %in% sample_nodes$node)

g2 <- graph_from_data_frame(net_sam,
                            directed = TRUE,
                            vertices = sample_nodes)

# colors based on party
V(g2)$color <- ifelse(V(g2)$party == "D", "blue", 
                      ifelse(V(g2)$party == "R", "red", "gray"))

# color based on weight
E(g2)$color <- ifelse(E(g2)$weight > .025, "darkred", "black")

plot(g2,
     edge.width = 2,
     edge.color = E(g2)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     edge.color = "black",
     vertex.color = V(g2)$color, 
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Subset of Nodes and Edges")
```

To explore a subset of the network, we first filtered the nodes based on their region (Midwest and South). After narrowing down the dataset to these two regions, we randomly selected n=25 nodes to analyze further. This sampling ensures that we focus on a manageable portion of the network while retaining the regional diversity we are interested in. We then extracted the corresponding edges that connect these sampled nodes and created a subgraph for visualization. In this plot, nodes are colored according to their region: Midwest nodes are colored orange and South nodes are colored purple. The edges are colored based on their weight, with higher-weighted connections shown in dark red. This approach allows us to examine the structure of a smaller, region-specific portion of the network.

```{r}
# sample from node attributes, then match to corresponding connections in the network
set.seed(123)

# filter the nodes by region (Midwest and South)
filtered_nodes <- cnet_node_attributes[cnet_node_attributes$region %in% c("Midwest", "South"), ]

# random sample from the filtered nodes
sample_nodes <- filtered_nodes[sample(nrow(filtered_nodes), size = 25), ]

# make sure attributes and nodes match
id_node <- sample_nodes$node
id_from <- network_df$from
id_to <- network_df$to
net_sam <- data.frame(from = double(),
                      to = integer(),
                      weight = double())

for (i in id_node) {
  if (i %in% id_to | i %in% id_from) {
    matches_from <- subset(network_df, from == i)
    matches_to <- subset(network_df, to == i)
    net_sam <- rbind(net_sam, matches_from, matches_to)
  }
}

# only keep the sampled nodes
net_sam <- subset(net_sam, from %in% sample_nodes$node & to %in% sample_nodes$node)

# subgraph from the sampled nodes and filtered edges
g2 <- graph_from_data_frame(net_sam,
                            directed = TRUE,
                            vertices = sample_nodes)

# colors based on region
V(g2)$color <- ifelse(V(g2)$region == "Midwest", "orange", 
                      ifelse(V(g2)$region == "South", "purple", "gray"))

# colors based on weight
E(g2)$color <- ifelse(E(g2)$weight > 0.025, "darkred", "black")

plot(g2,
     edge.width = 2,
     edge.color = E(g2)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     vertex.color = V(g2)$color, 
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Random Sample of 25 Nodes (Filtered by Midwest and South Regions)")
```
# Centrality Metrics

Centrality metrics are node specific measures that aim to quantify the importance of a node in a network. While there there are many different centrality metrics, we will focus on the following:

- Degree: The number of edges that a particular node has
- Betweenness: How frequently a particular node lies along the shortest path between any two other nodes
- Closeness: Inverse of the sum of the shortest path length between that node and every other node in the network

The below code chunk shows how we can calculate these centrality metrics for our network data.

```{r}
degree_metric <- tibble(degree = degree(cnet_igraph, mode = "all"), node = 1:length(degree(cnet_igraph, mode = "all")))
closeness_metric <- tibble(closeness = closeness(cnet_igraph, mode = "all"), node = 1:length(closeness(cnet_igraph, mode = "all")))
betweenness_metric <- tibble(betweenness = betweenness(cnet_igraph), node = 1:length(betweenness(cnet_igraph)))

degree_metric %>%
  head()

closeness_metric %>%
  head()

betweenness_metric %>%
  head()
```

Next we want to find what nodes in our network are the most central based off of these metrics. The code below creates tables with the top five nodes based off of each metric.

```{r}
highest_5_degree <- tibble(degree = degree(cnet_igraph, mode = "all"), node = 1:length(degree(cnet_igraph))) |>
  arrange(-degree) |>
  slice(1:5)


cnet_node_attributes |>
  filter(cnet_node_attributes$node %in% highest_5_degree$node) |>
  select(node, congressperson) |>
  inner_join(highest_5_degree) |>
  select(-node) |>
  arrange(-degree) |>
  kableExtra::kable() |>
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)

highest_5_closeness <- tibble(closeness = closeness(cnet_igraph, mode = "all"), node = 1:length(closeness(cnet_igraph, mode = "all"))) |>
  arrange(-closeness) |>
  slice(1:5)

cnet_node_attributes |>
  filter(cnet_node_attributes$node %in% highest_5_closeness$node) |>
  select(node, congressperson) |>
  inner_join(highest_5_closeness) |>
  select(-node) |>
  arrange(-closeness) |>
  kableExtra::kable() |>
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)


highest_5_betweenness <- tibble(betweenness = betweenness(cnet_igraph), node = 1:length(betweenness(cnet_igraph))) |>
  arrange(-betweenness) |>
  slice(1:5)

cnet_node_attributes |>
  filter(cnet_node_attributes$node %in% highest_5_betweenness$node) |>
  select(node, congressperson) |>
  inner_join(highest_5_betweenness) |>
  select(-node) |>
  arrange(-betweenness) |>
  kableExtra::kable() |>
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)
```

As we can see from the above tables, Kevin McCarthy is present in all five of the tables, which implies that he is highly central to the network. 

# Graph/Subgraph Metrics

Graph and subgraphs metrics are used to measure qualities of the network as a whole rather than looking at each individual node as we did with centrality networks. The metrics we will be looking at are:

- Transitivity: The probability that if some node A – node B, and node B – node C, then node A – node C
- Edge Density: Ratio of actual number of edges to total possible edges
- Mean Distance: Mean of the smallest distance between two nodes
- Reciprocity: In a *directed* network, the probability that if node A – node B, then node B – node A

First we are going to create a few important subgraphs including the Democratic and Republican subgraphs, the House and Senate subgraphs, and the subgraphs for each region.

```{r}
cnet_subgraph_dem <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "party"
      ) %>%
      `==`("D") 
  )

cnet_subgraph_rep <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "party"
      ) %>%
      `==`("R") 
  )

cnet_subgraph_senate <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "chamber"
      ) %>%
      `==`("Senate")
  )

cnet_subgraph_house <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "chamber"
      ) %>%
      `==`("House")
  )

cnet_subgraph_midwest <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "region"
      ) %>%
      `==`("Midwest") %>%
      replace_na(FALSE)
  )

cnet_subgraph_west <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "region"
      ) %>%
      `==`("West") %>%
      replace_na(FALSE)
  )

cnet_subgraph_south <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "region"
      ) %>%
      `==`("South") %>%
      replace_na(FALSE)
  )

cnet_subgraph_northeast <- cnet_igraph %>%
  subgraph(
    cnet_igraph %>%
      vertex_attr(
        "region"
      ) %>%
      `==`("Northeast") %>%
      replace_na(FALSE)
  )
```

Next we will calculate the metrics for each of the subgraphs and the overall graph and use the `kable` package to display the results.

```{r}
graphs <- paste(rep("cnet_subgraph", 8), 
                c("dem", "rep", "house", "senate", "midwest", "west", "south", "northeast"),
                sep = "_")

metrics <- c("reciprocity", "transitivity", "edge_density", "mean_distance")

graph_metrics <- lapply(c("cnet_igraph", graphs), 
       function(graph) {
         lapply(metrics,
                function(metric) {
                  get(metric, mode = "function")(get(graph))
                })
})

graph_metrics %>% 
  unlist() %>%
  matrix(
    ncol = length(metrics),
    byrow = TRUE
  ) %>%
  `colnames<-`(metrics) %>%
  `rownames<-`(c("overall", c("dem", "rep", "house", "senate", "midwest", "west", "south", "northeast"))) %>%
  kable()
```

In the table above, we can see that all of the subgraphs have a much higher edge density than the overall graph. This makes sense as the sugraphs only contain observations that share a certain attribute in common, and we would generally expect that people on twitter interact more often with people they are similar with. However, this does bring up the question: How can we tell if these differences are statistically significant?


# Hypothesis Testing

In order to formally test whether these differences are statistically significant, we will need to find a distribution that our test statistics (i.e., our subgraph metrics) can be compared to in order to obtain a $p$-value. One way to do this is to repeatedly randomly sample subgraphs of the same size from the overall graph and calculate the metric of interest on the randomly sampled subgraphs. We then can use these metrics as a null distribution of the metric of interest. To help us perform this procedure, we will define a function called `resample.t.test()` which will follow these steps to calculate a $p$-value given a specific graph, subgraph, statistic, and $n$, the number of random samples to perform. We then apply this function to the subgraphs and metrics that we looked at in the previous section.

```{r, cache = TRUE}
set.seed(12132024)

# resampling t-test to compare statistic of a subgraph to the overall graph
resample.t.test <- function(graph, subgraph, statistic, n, type = c("upper", "lower", "two-tailed")) {
  
  # get number of nodes in graph and subgraph
  n.graph <- graph %>% length()
  n.subgraph <- subgraph %>% length()
  
  # extract function to get statistic
  statistic <- get(statistic, mode = "function")
  
  # calculate distribution of the statistic of interest through random sampling
  stat.dist <- lapply(
    1:n,
    function(i) {
      graph %>%
        subgraph(
          sample(n.graph, n.subgraph)
        ) %>%
        statistic()
    }
  ) %>% unlist()
  
  # calculate mean of the distribution
  dist.mean <- mean(stat.dist)
  
  # calculate test statistic
  test.stat <- subgraph %>% statistic()
  
  
  # calculate p-value
  if (type == "upper") {
    pval <- sum(stat.dist >= test.stat)/n
  }
  else if (type == "lower") {
    pval <- sum(stat.dist <= test.stat)/n
  }
  else if (type == "two-tailed") {
    pval <- sum(stat.dist >= dist.mean + abs(test.stat - dist.mean))/n + 
      sum(abs(stat.dist <= dist.mean - abs(test.stat - dist.mean)))/n
  }
  

  out <- list(
    dist = stat.dist,
    stat = test.stat,
    pval = pval
  )
  
  return(out)
}

# prepare matrix to store t-test results
t.test.results <- matrix(
  data = rep(rep(0, length(groups)), length(metrics)),
  nrow = length(graphs), 
  ncol = length(metrics), 
  dimnames = (list(c("dem", "rep", "house", "senate", "midwest", "west", "south", "northeast"), metrics))
)

# perform t-tests on subgraph metrics
for (i in 1:length(graphs)) {
  for (j in 1:length(metrics)) {
    t.test.results[i,j] <- resample.t.test(cnet_igraph, get(graphs[i]), metrics[j], 10000, "two-tailed")$pval
  }
}
```

The results of our hypothesis test are shown in the following table.

```{r}
# print results
t.test.results %>%
  kable(
    caption = "Subgraph Metric p-values"
  )
```

However, since we performed multiple hypothesis tests, we will need to correct our $p$-values to account for the fact that the individual Type I Error rates compound over multiple test. Here, we will use the Benjamini-Yekuteili correction.

```{r}
# apply benjamini-yekuteili correction and print results
t.test.results %>%
  as.data.frame() %>%
  mutate(
    subgraph = row.names(.),
    .before = "reciprocity"
  ) %>%
  `row.names<-`(NULL) %>%
  pivot_longer(
    -subgraph,
    names_to = "metric",
    values_to = "p.value"
  ) %>%
  arrange(
    p.value
  ) %>%
  mutate(
    i = row_number()
  ) %>%
  group_by(i) %>%
  mutate(
    p.by = nrow(.)*sum(1/1:i)*p.value/i
  ) %>%
  ungroup() %>%
  select(
    -i,-p.value
  ) %>%
  pivot_wider(
    names_from = metric,
    values_from = p.by
  ) %>%
  relocate(
    reciprocity,
    transitivity,
    .before = "edge_density"
  ) %>%
  kable(
    caption = "Benjamini-Yekuteili Corrected Subgraph Metric p-values"
  )
```

We can now draw conclusions for our hypothesis tests with these corrected $p$-values. At the $\alpha=0.05$ significance level, we can conclude that the edge density of all subgraphs is different from the overall graph. Additionally, the transitivity of the Democratic, Republican, House, and Senate subgraphs are all different from the overall graph, and the mean distance of the Democratic and the Senate subgraphs are also different from the overall graph. The results for the edge density in particular indicate that these node attributes do play a significant factor in how members of Congress interact on Twitter: members have a greater tendency to interact with other members of the same party, chamber, state, and region.

# Adjacency Matrices

```{r, cache = TRUE}
# convert igraph object into an adjacency matrix
cnet_adj <- as_adjacency_matrix(cnet_igraph)

# define helper function to reorder adjacency matrix based on particular node attributes
reorder_cnet_adj <- function(adj_mat, attribute) {
  
  # load in node attributes
  node_attributes <- read_csv("data/congress_node_attributes.csv",
                              show_col_types = FALSE)
  
  # obtain new order by arranging based on attribute
  new_order <- node_attributes %>% 
    mutate(
      rand_order = sample(node)
    ) %>%
    arrange(
      get(attribute), rand_order
    ) %>%
    mutate(
      new_order = row_number()
    ) %>%
    arrange(
      node
    ) %>%
    pull(
      new_order
    )
  
  # reorder adjancency matrix based on the new order
  new_adj_mat <- adj_mat
  for (i in 1:475) {
    for (j in 1:475) {
      new_adj_mat[new_order[i], new_order[j]] <- adj_mat[i,j]
    }
  }
  
  return(new_adj_mat)
}

# generate adjacency matrices ordered by each set of node attributes
cnet_adj_chamber <- reorder_cnet_adj(cnet_adj, "chamber")
cnet_adj_party <- reorder_cnet_adj(cnet_adj, "party")
cnet_adj_state <- reorder_cnet_adj(cnet_adj, "state")
cnet_adj_region <- reorder_cnet_adj(cnet_adj, "region")
```

```{r}
cnet_adj_chamber %>%
  Matrix() %>%
  image(
    col.regions = c("black"),
    sub = NULL,
    xlab = NULL,
    ylab = NULL,
    main = "Adjacency Matrix Ordered by Chamber"
  )

cnet_adj_party %>%
  Matrix() %>%
  image(
    col.regions = c("black"),
    sub = NULL,
    xlab = NULL,
    ylab = NULL,
    main = "Adjacency Matrix Ordered by Party"
  )

cnet_adj_state %>%
  Matrix() %>%
  image(
    col.regions = c("black"),
    sub = NULL,
    xlab = NULL,
    ylab = NULL,
    main = "Adjacency Matrix Ordered by State"
  )

cnet_adj_region %>%
  Matrix() %>%
  image(
    col.regions = c("black"),
    sub = NULL,
    xlab = NULL,
    ylab = NULL,
    main = "Adjacency Matrix Ordered by Region"
  )
```

# Community Detection

Community detection involves identifying groups of vertices within a graph that are more densely connected to each other than to the rest of the network. Since our data represents a weighted, directed network, we will use the Walktrap algorithm, which is better suited for such networks compared to the Louvain method, which requires an undirected graph. This simulates random walks on the graph to detect communities.

Below, we will explore four methods for reducing the complexity of our community detection graphs: filtering edges by weight, applying random sampling to the edges, sampling a subset of nodes, and pruning edges based on node degree.

To avoid creating an overly dense graph, we will reduce its complexity by using a random sample from the data visualization portion. Additionally, we have filtered the edges based on their weights, removing connections that are less significant. Specifically, we excluded edges with weights below 0.003, as the median weight across all edges is 0.0025, which helps focus on the most meaningful connections in the network.

```{r}
# remove edges with weight below 0.003
g2_filtered <- delete_edges(g2, E(g2)[weight < 0.003])

# perform Walktrap community detection on the filtered graph
community_walktrap <- cluster_walktrap(g2_filtered)

# assign colors to the communities
V(g2_filtered)$color <- factor(community_walktrap$membership)

plot(g2_filtered,
     edge.width = 2,
     edge.color = E(g2_filtered)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     vertex.color = V(g2_filtered)$color,
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Community Detection (Filtered Graph with Walktrap)")
```

We can also apply random sampling to reduce the size and density of the graph, while preserving its underlying structure.

```{r}
# total number of edges
total_edges <- ecount(g2)

# sample from edges, ensuring the sample size doesn't exceed the number of edges
set.seed(123)
sample_size <- min(100, total_edges)

sampled_edges <- sample(E(g2), size = sample_size)  # Sample edges

# new graph with the sampled edges
g2_sampled <- subgraph.edges(g2, sampled_edges)

# Walktrap community detection on the sampled graph
community_walktrap <- cluster_walktrap(g2_sampled)

V(g2_sampled)$color <- factor(community_walktrap$membership)

plot(g2_sampled,
     edge.width = 2,
     edge.color = E(g2_sampled)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     vertex.color = V(g2_sampled)$color,
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Community Detection (Sampled Graph with Walktrap)")
```

We can also sample a subset of nodes, which simplifies the analysis by focusing on specific nodes.

```{r}
# sample 25 nodes from the graph
set.seed(123)
sampled_nodes <- sample(V(g2), size = 25)

# subgraph containing only the sampled nodes
g2_sampled_nodes <- induced_subgraph(g2, vids = sampled_nodes)

# perform Walktrap community detection on the sampled graph
community_walktrap <- cluster_walktrap(g2_sampled_nodes)

V(g2_sampled_nodes)$color <- factor(community_walktrap$membership)

plot(g2_sampled_nodes,
     edge.width = 2,
     edge.color = E(g2_sampled_nodes)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     vertex.color = V(g2_sampled_nodes)$color,
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Community Detection (Sampled Nodes with Walktrap)")
```

We can also remove edges between nodes with low degrees, under the assumption that highly connected nodes play a more significant role in community detection.

```{r}
# remove edges between nodes with low degrees
low_degree_nodes <- V(g2)[degree(g2) < 3]
g2_pruned <- delete_edges(g2, E(g2)[.from(low_degree_nodes) | .to(low_degree_nodes)])

# Walktrap community detection on the pruned graph
community_walktrap <- cluster_walktrap(g2_pruned)

V(g2_pruned)$color <- factor(community_walktrap$membership)

plot(g2_pruned,
     edge.width = 2,
     edge.color = E(g2_pruned)$color,
     edge.curved = 0.2,
     edge.arrow.size = 0.5,
     vertex.color = V(g2_pruned)$color,
     vertex.size = 30,
     vertex.frame.color = "black",
     vertex.label.color = "white",
     layout = layout_with_fr,
     main = "Community Detection (Pruned Graph with Walktrap)")
```
